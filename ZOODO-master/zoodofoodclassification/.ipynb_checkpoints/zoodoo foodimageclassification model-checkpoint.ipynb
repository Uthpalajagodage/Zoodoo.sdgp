{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41a6777d5e67dc652f57ce9681b4c44dc44152be",
    "id": "uNaVQGQ9tQRr"
   },
   "source": [
    "# **zoodo food classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "dd82702380162e9587a0eae2f644dae2764f93c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imported\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "print (\"all imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "70f06e9a535b5f32ad9d927fc00e767dd72f17dd",
    "id": "JOZZbCDoP-Hy",
    "outputId": "99f6277e-0b8e-4541-a9b4-cce1a98f5b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "\n",
      "{\"items\": [{\"name\": \"french fries\", \"calories\": 312.5, \"serving_size_g\": 100.0, \"fat_total_g\": 14.4, \"fat_saturated_g\": 2.3, \"protein_g\": 3.4, \"sodium_mg\": 209, \"potassium_mg\": 123, \"cholesterol_mg\": 0, \"carbohydrates_total_g\": 42.1, \"fiber_g\": 3.8, \"sugar_g\": 0.3}]}\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is enabled\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "api_url = 'https://api.calorieninjas.com/v1/nutrition?query='\n",
    "query = 'french fries'\n",
    "response = requests.get(api_url + query, headers={'X-Api-Key': 's9S3fiY9BWYZtpCebS71Rg==Qk1nbauJKhKE9k8R'})\n",
    "if response.status_code == requests.codes.ok:\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9a3e091f8d5db4be5a553a2fd23970dde7c649f2",
    "id": "yy_pAK35Rbdi",
    "outputId": "9b374f07-961a-4878-85a2-86589b2f68cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito',\n",
       " 'bruschetta',\n",
       " 'caesar_salad',\n",
       " 'cannoli',\n",
       " 'caprese_salad',\n",
       " 'carrot_cake',\n",
       " 'ceviche',\n",
       " 'cheesecake',\n",
       " 'cheese_plate',\n",
       " 'chicken_curry',\n",
       " 'chicken_quesadilla',\n",
       " 'chicken_wings',\n",
       " 'chocolate_cake',\n",
       " 'chocolate_mousse',\n",
       " 'churros',\n",
       " 'clam_chowder',\n",
       " 'club_sandwich',\n",
       " 'crab_cakes',\n",
       " 'creme_brulee',\n",
       " 'croque_madame',\n",
       " 'cup_cakes',\n",
       " 'deviled_eggs',\n",
       " 'donuts',\n",
       " 'dumplings',\n",
       " 'edamame',\n",
       " 'eggs_benedict',\n",
       " 'escargots',\n",
       " 'falafel',\n",
       " 'filet_mignon',\n",
       " 'fish_and_chips',\n",
       " 'foie_gras',\n",
       " 'french_fries',\n",
       " 'french_onion_soup',\n",
       " 'french_toast',\n",
       " 'fried_calamari',\n",
       " 'fried_rice',\n",
       " 'frozen_yogurt',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'greek_salad',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'grilled_salmon',\n",
       " 'guacamole',\n",
       " 'gyoza',\n",
       " 'hamburger',\n",
       " 'hot_and_sour_soup',\n",
       " 'hot_dog',\n",
       " 'huevos_rancheros',\n",
       " 'hummus',\n",
       " 'ice_cream',\n",
       " 'lasagna',\n",
       " 'lobster_bisque',\n",
       " 'lobster_roll_sandwich',\n",
       " 'macaroni_and_cheese',\n",
       " 'macarons',\n",
       " 'miso_soup',\n",
       " 'mussels',\n",
       " 'nachos',\n",
       " 'omelette',\n",
       " 'onion_rings',\n",
       " 'oysters',\n",
       " 'pad_thai',\n",
       " 'paella',\n",
       " 'pancakes',\n",
       " 'panna_cotta',\n",
       " 'peking_duck',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'pork_chop',\n",
       " 'poutine',\n",
       " 'prime_rib',\n",
       " 'pulled_pork_sandwich',\n",
       " 'ramen',\n",
       " 'ravioli',\n",
       " 'red_velvet_cake',\n",
       " 'risotto',\n",
       " 'samosa',\n",
       " 'sashimi',\n",
       " 'scallops',\n",
       " 'seaweed_salad',\n",
       " 'shrimp_and_grits',\n",
       " 'spaghetti_bolognese',\n",
       " 'spaghetti_carbonara',\n",
       " 'spring_rolls',\n",
       " 'steak',\n",
       " 'strawberry_shortcake',\n",
       " 'sushi',\n",
       " 'tacos',\n",
       " 'takoyaki',\n",
       " 'tiramisu',\n",
       " 'tuna_tartare',\n",
       " 'waffles']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects\\\\sathmika-SDGP\\\\foodclassification\\\\foodclassification\\\\kaggle\\\\input\\\\food-101\\\\food-101'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c3f4490c55a470c25cf5f92f131f21701782e645",
    "id": "jdIDm6tkSwqY",
    "outputId": "8a3b9226-69ff-4bba-89fc-b303d1e10d7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classes.txt',\n",
       " 'labels.txt',\n",
       " 'test.json',\n",
       " 'test.txt',\n",
       " 'train.json',\n",
       " 'train.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder_path+'/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3267-E0E0\n",
      "\n",
      " Directory of C:\\xampp\\htdocs\\Zoodo\\foodclassification\n",
      "\n",
      "03/04/2023  11:31 PM    <DIR>          .\n",
      "03/04/2023  11:31 PM    <DIR>          ..\n",
      "03/04/2023  07:41 PM    <DIR>          .ipynb_checkpoints\n",
      "03/04/2023  07:37 PM    <DIR>          foodclassification\n",
      "03/01/2023  07:52 PM           473,603 food-image-classification-963298.ipynb\n",
      "03/04/2023  07:51 PM    <DIR>          kaggle\n",
      "03/04/2023  11:31 PM            69,303 multiclass-food-classification-using-tensor-935e9f.ipynb\n",
      "03/01/2023  07:07 PM         4,185,003 ssd_mobilenet_v1_1_metadata_1 (1).tflite\n",
      "               3 File(s)      4,727,909 bytes\n",
      "               5 Dir(s)  40,695,025,664 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple_pie/1005649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\xampp\\htdocs\\Zoodo\\foodclassification\\kaggle\\input\\food-101\\food-101\\meta\\train.txt') as f:\n",
    "    line = f.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "2f606b4a970498cf9303c2d393605494b51bc3f6",
    "id": "a3yfov0gQocW",
    "outputId": "8ee3f518-986e-4135-e987-c61cd9b5b53c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple_pie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!head food-101/meta/classes.txt\n",
    "with open(r'C:\\xampp\\htdocs\\Zoodo\\foodclassification\\kaggle\\input\\food-101\\food-101\\meta\\classes.txt') as f:\n",
    "    line = f.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4af37d46992f3b2aa7b74efcb5102751b167914e",
    "id": "motIEZu_TVih"
   },
   "source": [
    "### **Visualize random image from each of the 101 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da6910e8bb064b76c17e07f0a2e0e23ebdefbbfa",
    "id": "Jfif27Pr5KEn",
    "outputId": "a451ddd4-2beb-4d36-eb00-000ed2f23286"
   },
   "outputs": [],
   "source": [
    "# Visualize the data, showing one image per class from 101 classes\n",
    "rows = 17\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
    "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
    "data_dir = \"food-101/images/\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "food_id = 0\n",
    "for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    try:\n",
    "      food_selected = foods_sorted[food_id] \n",
    "      food_id += 1\n",
    "    except:\n",
    "      break\n",
    "    if food_selected == '.DS_Store':\n",
    "        continue\n",
    "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
    "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
    "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
    "    ax[i][j].imshow(img)\n",
    "    ax[i][j].set_title(food_selected, pad = 10)\n",
    "    \n",
    "plt.setp(ax, xticks=[],yticks=[])\n",
    "plt.tight_layout()\n",
    "# https://matplotlib.org/users/tight_layout_guide.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a8300cde1146c50e672079b44346e723d813702",
    "id": "KIgareCETmct"
   },
   "source": [
    "### **Split the image data into train and test using train.txt and test.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "d6c87e52c1af18e3243f1cb72b5834941828b286",
    "id": "xB0XMUX_5KMQ"
   },
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src,dest):\n",
    "  classes_images = defaultdict(list)\n",
    "  with open(filepath, 'r') as txt:\n",
    "      paths = [read.strip() for read in txt.readlines()]\n",
    "      for p in paths:\n",
    "        food = p.split('/')\n",
    "        classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "      os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "  print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3267-E0E0\n",
      "\n",
      " Directory of C:\\xampp\\htdocs\\Zoodo\\foodclassification\n",
      "\n",
      "03/04/2023  11:47 PM    <DIR>          .\n",
      "03/04/2023  11:47 PM    <DIR>          ..\n",
      "03/04/2023  07:41 PM    <DIR>          .ipynb_checkpoints\n",
      "03/04/2023  07:37 PM    <DIR>          foodclassification\n",
      "03/01/2023  07:52 PM           473,603 food-image-classification-963298.ipynb\n",
      "03/04/2023  07:51 PM    <DIR>          kaggle\n",
      "03/04/2023  11:47 PM            65,135 multiclass-food-classification-using-tensor-935e9f.ipynb\n",
      "03/01/2023  07:07 PM         4,185,003 ssd_mobilenet_v1_1_metadata_1 (1).tflite\n",
      "               3 File(s)      4,723,741 bytes\n",
      "               5 Dir(s)  45,757,820,928 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "786cdb3d60ebcdddb4c2875f9e0b4508c5210fc1",
    "id": "LSgcYcqy5KUd",
    "outputId": "7e65498b-bcd8-4209-87e8-bdc1a8c37b4e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train data...\n",
      "\n",
      "Copying images into  apple_pie\n",
      "\n",
      "Copying images into  baby_back_ribs\n",
      "\n",
      "Copying images into  baklava\n",
      "\n",
      "Copying images into  beef_carpaccio\n",
      "\n",
      "Copying images into  beef_tartare\n",
      "\n",
      "Copying images into  beet_salad\n",
      "\n",
      "Copying images into  beignets\n",
      "\n",
      "Copying images into  bibimbap\n",
      "\n",
      "Copying images into  bread_pudding\n",
      "\n",
      "Copying images into  breakfast_burrito\n",
      "\n",
      "Copying images into  bruschetta\n",
      "\n",
      "Copying images into  caesar_salad\n",
      "\n",
      "Copying images into  cannoli\n",
      "\n",
      "Copying images into  caprese_salad\n",
      "\n",
      "Copying images into  carrot_cake\n",
      "\n",
      "Copying images into  ceviche\n",
      "\n",
      "Copying images into  cheesecake\n",
      "\n",
      "Copying images into  cheese_plate\n",
      "\n",
      "Copying images into  chicken_curry\n",
      "\n",
      "Copying images into  chicken_quesadilla\n",
      "\n",
      "Copying images into  chicken_wings\n",
      "\n",
      "Copying images into  chocolate_cake\n",
      "\n",
      "Copying images into  chocolate_mousse\n",
      "\n",
      "Copying images into  churros\n",
      "\n",
      "Copying images into  clam_chowder\n",
      "\n",
      "Copying images into  club_sandwich\n",
      "\n",
      "Copying images into  crab_cakes\n",
      "\n",
      "Copying images into  creme_brulee\n",
      "\n",
      "Copying images into  croque_madame\n",
      "\n",
      "Copying images into  cup_cakes\n",
      "\n",
      "Copying images into  deviled_eggs\n",
      "\n",
      "Copying images into  donuts\n",
      "\n",
      "Copying images into  dumplings\n",
      "\n",
      "Copying images into  edamame\n",
      "\n",
      "Copying images into  eggs_benedict\n",
      "\n",
      "Copying images into  escargots\n",
      "\n",
      "Copying images into  falafel\n",
      "\n",
      "Copying images into  filet_mignon\n",
      "\n",
      "Copying images into  fish_and_chips\n",
      "\n",
      "Copying images into  foie_gras\n",
      "\n",
      "Copying images into  french_fries\n",
      "\n",
      "Copying images into  french_onion_soup\n",
      "\n",
      "Copying images into  french_toast\n",
      "\n",
      "Copying images into  fried_calamari\n",
      "\n",
      "Copying images into  fried_rice\n",
      "\n",
      "Copying images into  frozen_yogurt\n",
      "\n",
      "Copying images into  garlic_bread\n",
      "\n",
      "Copying images into  gnocchi\n",
      "\n",
      "Copying images into  greek_salad\n",
      "\n",
      "Copying images into  grilled_cheese_sandwich\n",
      "\n",
      "Copying images into  grilled_salmon\n",
      "\n",
      "Copying images into  guacamole\n",
      "\n",
      "Copying images into  gyoza\n",
      "\n",
      "Copying images into  hamburger\n",
      "\n",
      "Copying images into  hot_and_sour_soup\n",
      "\n",
      "Copying images into  hot_dog\n",
      "\n",
      "Copying images into  huevos_rancheros\n",
      "\n",
      "Copying images into  hummus\n",
      "\n",
      "Copying images into  ice_cream\n",
      "\n",
      "Copying images into  lasagna\n",
      "\n",
      "Copying images into  lobster_bisque\n",
      "\n",
      "Copying images into  lobster_roll_sandwich\n",
      "\n",
      "Copying images into  macaroni_and_cheese\n",
      "\n",
      "Copying images into  macarons\n",
      "\n",
      "Copying images into  miso_soup\n",
      "\n",
      "Copying images into  mussels\n",
      "\n",
      "Copying images into  nachos\n",
      "\n",
      "Copying images into  omelette\n",
      "\n",
      "Copying images into  onion_rings\n",
      "\n",
      "Copying images into  oysters\n",
      "\n",
      "Copying images into  pad_thai\n",
      "\n",
      "Copying images into  paella\n",
      "\n",
      "Copying images into  pancakes\n",
      "\n",
      "Copying images into  panna_cotta\n",
      "\n",
      "Copying images into  peking_duck\n",
      "\n",
      "Copying images into  pho\n",
      "\n",
      "Copying images into  pizza\n",
      "\n",
      "Copying images into  pork_chop\n",
      "\n",
      "Copying images into  poutine\n",
      "\n",
      "Copying images into  prime_rib\n",
      "\n",
      "Copying images into  pulled_pork_sandwich\n",
      "\n",
      "Copying images into  ramen\n",
      "\n",
      "Copying images into  ravioli\n",
      "\n",
      "Copying images into  red_velvet_cake\n",
      "\n",
      "Copying images into  risotto\n",
      "\n",
      "Copying images into  samosa\n",
      "\n",
      "Copying images into  sashimi\n",
      "\n",
      "Copying images into  scallops\n",
      "\n",
      "Copying images into  seaweed_salad\n",
      "\n",
      "Copying images into  shrimp_and_grits\n",
      "\n",
      "Copying images into  spaghetti_bolognese\n",
      "\n",
      "Copying images into  spaghetti_carbonara\n",
      "\n",
      "Copying images into  spring_rolls\n",
      "\n",
      "Copying images into  steak\n",
      "\n",
      "Copying images into  strawberry_shortcake\n",
      "\n",
      "Copying images into  sushi\n",
      "\n",
      "Copying images into  tacos\n",
      "\n",
      "Copying images into  takoyaki\n",
      "\n",
      "Copying images into  tiramisu\n",
      "\n",
      "Copying images into  tuna_tartare\n",
      "\n",
      "Copying images into  waffles\n",
      "Copying Done!\n"
     ]
    }
   ],
   "source": [
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "print(\"Creating train data...\")\n",
    "prepare_data(folder_path+'/meta/train.txt', folder_path+'/images', folder_path+'/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "ba85577e0ef10c768e000ecf32dee36566d52599",
    "id": "JI65wZgT5Kb-",
    "outputId": "2e71e6bc-43de-4ea3-f5d6-a660c4a3dc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data...\n",
      "\n",
      "Copying images into  apple_pie\n",
      "\n",
      "Copying images into  baby_back_ribs\n",
      "\n",
      "Copying images into  baklava\n",
      "\n",
      "Copying images into  beef_carpaccio\n",
      "\n",
      "Copying images into  beef_tartare\n",
      "\n",
      "Copying images into  beet_salad\n",
      "\n",
      "Copying images into  beignets\n",
      "\n",
      "Copying images into  bibimbap\n",
      "\n",
      "Copying images into  bread_pudding\n",
      "\n",
      "Copying images into  breakfast_burrito\n",
      "\n",
      "Copying images into  bruschetta\n",
      "\n",
      "Copying images into  caesar_salad\n",
      "\n",
      "Copying images into  cannoli\n",
      "\n",
      "Copying images into  caprese_salad\n",
      "\n",
      "Copying images into  carrot_cake\n",
      "\n",
      "Copying images into  ceviche\n",
      "\n",
      "Copying images into  cheesecake\n",
      "\n",
      "Copying images into  cheese_plate\n",
      "\n",
      "Copying images into  chicken_curry\n",
      "\n",
      "Copying images into  chicken_quesadilla\n",
      "\n",
      "Copying images into  chicken_wings\n",
      "\n",
      "Copying images into  chocolate_cake\n",
      "\n",
      "Copying images into  chocolate_mousse\n",
      "\n",
      "Copying images into  churros\n",
      "\n",
      "Copying images into  clam_chowder\n",
      "\n",
      "Copying images into  club_sandwich\n",
      "\n",
      "Copying images into  crab_cakes\n",
      "\n",
      "Copying images into  creme_brulee\n",
      "\n",
      "Copying images into  croque_madame\n",
      "\n",
      "Copying images into  cup_cakes\n",
      "\n",
      "Copying images into  deviled_eggs\n",
      "\n",
      "Copying images into  donuts\n",
      "\n",
      "Copying images into  dumplings\n",
      "\n",
      "Copying images into  edamame\n",
      "\n",
      "Copying images into  eggs_benedict\n",
      "\n",
      "Copying images into  escargots\n",
      "\n",
      "Copying images into  falafel\n",
      "\n",
      "Copying images into  filet_mignon\n",
      "\n",
      "Copying images into  fish_and_chips\n",
      "\n",
      "Copying images into  foie_gras\n",
      "\n",
      "Copying images into  french_fries\n",
      "\n",
      "Copying images into  french_onion_soup\n",
      "\n",
      "Copying images into  french_toast\n",
      "\n",
      "Copying images into  fried_calamari\n",
      "\n",
      "Copying images into  fried_rice\n",
      "\n",
      "Copying images into  frozen_yogurt\n",
      "\n",
      "Copying images into  garlic_bread\n",
      "\n",
      "Copying images into  gnocchi\n",
      "\n",
      "Copying images into  greek_salad\n",
      "\n",
      "Copying images into  grilled_cheese_sandwich\n",
      "\n",
      "Copying images into  grilled_salmon\n",
      "\n",
      "Copying images into  guacamole\n",
      "\n",
      "Copying images into  gyoza\n",
      "\n",
      "Copying images into  hamburger\n",
      "\n",
      "Copying images into  hot_and_sour_soup\n",
      "\n",
      "Copying images into  hot_dog\n",
      "\n",
      "Copying images into  huevos_rancheros\n",
      "\n",
      "Copying images into  hummus\n",
      "\n",
      "Copying images into  ice_cream\n",
      "\n",
      "Copying images into  lasagna\n",
      "\n",
      "Copying images into  lobster_bisque\n",
      "\n",
      "Copying images into  lobster_roll_sandwich\n",
      "\n",
      "Copying images into  macaroni_and_cheese\n",
      "\n",
      "Copying images into  macarons\n",
      "\n",
      "Copying images into  miso_soup\n",
      "\n",
      "Copying images into  mussels\n",
      "\n",
      "Copying images into  nachos\n",
      "\n",
      "Copying images into  omelette\n",
      "\n",
      "Copying images into  onion_rings\n",
      "\n",
      "Copying images into  oysters\n",
      "\n",
      "Copying images into  pad_thai\n",
      "\n",
      "Copying images into  paella\n",
      "\n",
      "Copying images into  pancakes\n",
      "\n",
      "Copying images into  panna_cotta\n",
      "\n",
      "Copying images into  peking_duck\n",
      "\n",
      "Copying images into  pho\n",
      "\n",
      "Copying images into  pizza\n",
      "\n",
      "Copying images into  pork_chop\n",
      "\n",
      "Copying images into  poutine\n",
      "\n",
      "Copying images into  prime_rib\n",
      "\n",
      "Copying images into  pulled_pork_sandwich\n",
      "\n",
      "Copying images into  ramen\n",
      "\n",
      "Copying images into  ravioli\n",
      "\n",
      "Copying images into  red_velvet_cake\n",
      "\n",
      "Copying images into  risotto\n",
      "\n",
      "Copying images into  samosa\n",
      "\n",
      "Copying images into  sashimi\n",
      "\n",
      "Copying images into  scallops\n",
      "\n",
      "Copying images into  seaweed_salad\n",
      "\n",
      "Copying images into  shrimp_and_grits\n",
      "\n",
      "Copying images into  spaghetti_bolognese\n",
      "\n",
      "Copying images into  spaghetti_carbonara\n",
      "\n",
      "Copying images into  spring_rolls\n",
      "\n",
      "Copying images into  steak\n",
      "\n",
      "Copying images into  strawberry_shortcake\n",
      "\n",
      "Copying images into  sushi\n",
      "\n",
      "Copying images into  tacos\n",
      "\n",
      "Copying images into  takoyaki\n",
      "\n",
      "Copying images into  tiramisu\n",
      "\n",
      "Copying images into  tuna_tartare\n",
      "\n",
      "Copying images into  waffles\n",
      "Copying Done!\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data(folder_path+'/meta/test.txt', folder_path+'/images', folder_path+'/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101\n"
     ]
    }
   ],
   "source": [
    "cd D:\\\\Projects\\\\sathmika-SDGP\\\\foodclassification\\\\foodclassification\\\\kaggle\\\\input\\\\food-101\\\\food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b5a96c42b2af54aa994b86a58d2657b81786381b",
    "id": "Xccc8PJP5K1G",
    "outputId": "981ab583-491f-41ff-a128-d1f29c137775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in train folder\n",
      "24783\n"
     ]
    }
   ],
   "source": [
    "# Check how many files are in the train folder\n",
    "print(\"Total number of samples in train folder\")\n",
    "!dir /a /b /s train | find /v /c \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "492bb30a200d6cde501fbe2a6424c1c05a67c2e8",
    "id": "Iz3fjQw25K3-",
    "outputId": "b667062f-9acb-4be7-81ff-15347abdc750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in test folder\n",
      "8283\n"
     ]
    }
   ],
   "source": [
    "# Check how many files are in the test folder\n",
    "print(\"Total number of samples in test folder\")\n",
    "!dir /b /s test | find /v /c \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a9e9afbfe1fc303c23c06c27444b66988ab8e9d",
    "id": "upx61ukJiA8B"
   },
   "source": [
    "### **Fine tune vgg-16 Pretrained model using Food 101 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "# folder path\n",
    "path = r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101\\test'\n",
    "folders = 0\n",
    "\n",
    "for _, dirnames, filenames in os.walk(path):\n",
    "  # ^ this idiom means \"we won't be using this value\"\n",
    "    folders += len(dirnames)\n",
    "\n",
    "print (folders)\n",
    "num_of_classes=folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_gpu==2.10\n",
      "  Using cached tensorflow_gpu-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (0.31.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (58.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (15.0.6.1)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (23.3.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (3.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.51.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.16.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (4.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (2.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_gpu==2.10) (1.24.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow_gpu==2.10) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (2.2.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (2.16.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow_gpu==2.10) (3.2.2)\n",
      "Installing collected packages: keras, tensorflow-estimator, keras-preprocessing, tensorboard, tensorflow_gpu\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_gpu==2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8d08ece78ab731f7ac8a9b4b581e42e29093bcca",
    "id": "JBs1U7hZkp1U",
    "outputId": "83b079b8-2550-41db-fcac-961fb11c07fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24750 images belonging to 33 classes.\n",
      "Found 8250 images belonging to 33 classes.\n",
      "Epoch 1/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 2.2003 - accuracy: 0.4050\n",
      "Epoch 1: val_loss improved from inf to 1.10222, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 714s 453ms/step - loss: 2.2003 - accuracy: 0.4050 - val_loss: 1.1022 - val_accuracy: 0.6932\n",
      "Epoch 2/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 1.2176 - accuracy: 0.6740\n",
      "Epoch 2: val_loss improved from 1.10222 to 0.85696, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 285s 184ms/step - loss: 1.2176 - accuracy: 0.6740 - val_loss: 0.8570 - val_accuracy: 0.7629\n",
      "Epoch 3/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.7411\n",
      "Epoch 3: val_loss improved from 0.85696 to 0.66643, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 276s 179ms/step - loss: 0.9588 - accuracy: 0.7411 - val_loss: 0.6664 - val_accuracy: 0.8177\n",
      "Epoch 4/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.8248 - accuracy: 0.7805\n",
      "Epoch 4: val_loss improved from 0.66643 to 0.61334, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 278s 179ms/step - loss: 0.8248 - accuracy: 0.7805 - val_loss: 0.6133 - val_accuracy: 0.8319\n",
      "Epoch 5/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.7116 - accuracy: 0.8087\n",
      "Epoch 5: val_loss improved from 0.61334 to 0.56630, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 360s 233ms/step - loss: 0.7116 - accuracy: 0.8087 - val_loss: 0.5663 - val_accuracy: 0.8494\n",
      "Epoch 6/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.8350\n",
      "Epoch 6: val_loss did not improve from 0.56630\n",
      "1546/1546 [==============================] - 284s 184ms/step - loss: 0.6013 - accuracy: 0.8350 - val_loss: 0.5950 - val_accuracy: 0.8408\n",
      "Epoch 7/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.8492\n",
      "Epoch 7: val_loss did not improve from 0.56630\n",
      "1546/1546 [==============================] - 270s 175ms/step - loss: 0.5519 - accuracy: 0.8492 - val_loss: 0.6797 - val_accuracy: 0.8329\n",
      "Epoch 8/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8661\n",
      "Epoch 8: val_loss did not improve from 0.56630\n",
      "1546/1546 [==============================] - 273s 177ms/step - loss: 0.4867 - accuracy: 0.8661 - val_loss: 0.5958 - val_accuracy: 0.8432\n",
      "Epoch 9/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.4477 - accuracy: 0.8785\n",
      "Epoch 9: val_loss did not improve from 0.56630\n",
      "1546/1546 [==============================] - 271s 175ms/step - loss: 0.4477 - accuracy: 0.8785 - val_loss: 0.6514 - val_accuracy: 0.8358\n",
      "Epoch 10/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.8899\n",
      "Epoch 10: val_loss improved from 0.56630 to 0.56014, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 274s 177ms/step - loss: 0.4027 - accuracy: 0.8899 - val_loss: 0.5601 - val_accuracy: 0.8585\n",
      "Epoch 11/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8967\n",
      "Epoch 11: val_loss did not improve from 0.56014\n",
      "1546/1546 [==============================] - 255s 165ms/step - loss: 0.3678 - accuracy: 0.8967 - val_loss: 0.7216 - val_accuracy: 0.8248\n",
      "Epoch 12/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.9091\n",
      "Epoch 12: val_loss did not improve from 0.56014\n",
      "1546/1546 [==============================] - 253s 164ms/step - loss: 0.3307 - accuracy: 0.9091 - val_loss: 0.6124 - val_accuracy: 0.8510\n",
      "Epoch 13/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.9183\n",
      "Epoch 13: val_loss did not improve from 0.56014\n",
      "1546/1546 [==============================] - 253s 163ms/step - loss: 0.3013 - accuracy: 0.9183 - val_loss: 0.6774 - val_accuracy: 0.8420\n",
      "Epoch 14/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9234\n",
      "Epoch 14: val_loss improved from 0.56014 to 0.55925, saving model to D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.hdf5\n",
      "1546/1546 [==============================] - 254s 165ms/step - loss: 0.2793 - accuracy: 0.9234 - val_loss: 0.5593 - val_accuracy: 0.8623\n",
      "Epoch 15/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9308\n",
      "Epoch 15: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 253s 163ms/step - loss: 0.2566 - accuracy: 0.9308 - val_loss: 0.5908 - val_accuracy: 0.8547\n",
      "Epoch 16/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9310\n",
      "Epoch 16: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 252s 163ms/step - loss: 0.2527 - accuracy: 0.9310 - val_loss: 0.7309 - val_accuracy: 0.8358\n",
      "Epoch 17/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9341\n",
      "Epoch 17: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 254s 164ms/step - loss: 0.2379 - accuracy: 0.9341 - val_loss: 0.6293 - val_accuracy: 0.8578\n",
      "Epoch 18/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9425\n",
      "Epoch 18: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 257s 166ms/step - loss: 0.2043 - accuracy: 0.9425 - val_loss: 0.6570 - val_accuracy: 0.8552\n",
      "Epoch 19/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9434\n",
      "Epoch 19: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 254s 164ms/step - loss: 0.2003 - accuracy: 0.9434 - val_loss: 0.6701 - val_accuracy: 0.8476\n",
      "Epoch 20/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9489\n",
      "Epoch 20: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 251s 163ms/step - loss: 0.1817 - accuracy: 0.9489 - val_loss: 0.6617 - val_accuracy: 0.8629\n",
      "Epoch 21/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9503\n",
      "Epoch 21: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 256s 165ms/step - loss: 0.1730 - accuracy: 0.9503 - val_loss: 0.6889 - val_accuracy: 0.8467\n",
      "Epoch 22/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9518\n",
      "Epoch 22: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 253s 163ms/step - loss: 0.1764 - accuracy: 0.9518 - val_loss: 0.7235 - val_accuracy: 0.8478\n",
      "Epoch 23/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9533\n",
      "Epoch 23: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 257s 166ms/step - loss: 0.1646 - accuracy: 0.9533 - val_loss: 0.6902 - val_accuracy: 0.8482\n",
      "Epoch 24/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9584\n",
      "Epoch 24: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 252s 163ms/step - loss: 0.1505 - accuracy: 0.9584 - val_loss: 0.6707 - val_accuracy: 0.8553\n",
      "Epoch 25/25\n",
      "1546/1546 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9592\n",
      "Epoch 25: val_loss did not improve from 0.55925\n",
      "1546/1546 [==============================] - 259s 167ms/step - loss: 0.1458 - accuracy: 0.9592 - val_loss: 0.6686 - val_accuracy: 0.8670\n"
     ]
    }
   ],
   "source": [
    "# Clearing previous session\n",
    "K.clear_session()\n",
    "\n",
    "# Setting number of classes, image dimensions and other parameters\n",
    "n_classes = 33\n",
    "img_width, img_height = 299, 299\n",
    "train_data_dir = r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101\\train'\n",
    "validation_data_dir = r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\kaggle\\input\\food-101\\food-101\\test'\n",
    "nb_train_samples = 24750\n",
    "nb_validation_samples = 8250\n",
    "batch_size = 16\n",
    "\n",
    "# Defining image data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Loading the VGG16 model without the top layer and adding custom layers\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Adding the output layer with softmax activation\n",
    "predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "# Compiling the model with SGD optimizer and categorical crossentropy loss\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Defining callbacks\n",
    "checkpointer = ModelCheckpoint(filepath=r'D:Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.h5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger(r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\history_3class.log')\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size,\n",
    "                    epochs=25,\n",
    "                    verbose=1,\n",
    "                    callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "# Saving the model\n",
    "model.save(r'D:\\Projects\\sathmika-SDGP\\foodclassification\\foodclassification\\zodoofoodclassification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: keras in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.24.2)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.3-cp39-cp39-win_amd64.whl (10.9 MB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.3)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2366 sha256=43044aba8f15ab195b00259e2484573811ea7142605212b788f090a005a4455d\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\f8\\e0\\3d\\9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, pytz, pandas\n",
      "Successfully installed pandas-1.5.3 pytz-2022.7.1 sklearn-0.0.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow keras numpy pandas sklearn pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "558180f917fba895b9792328b234421c097f1ba0"
   },
   "outputs": [],
   "source": [
    "class_map_3 = train_generator.class_indices\n",
    "class_map_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "732521c21ce35b5be0d571cbe9d392d93755671c",
    "id": "KbDzLAHGpJXQ"
   },
   "source": [
    "### **Visualize the accuracy and loss plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27084e072edb2c961bfa6be87d80f273d32533c2",
    "id": "SjRm_AWZpPZm",
    "outputId": "42a0123b-d15d-4ffa-cba4-e92cd81b0324"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a73c830d2fbd841c9541628061313e4fd8506a51"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history,'FOOD101-Inceptionv3')\n",
    "plot_loss(history,'FOOD101-Inceptionv3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16347094046271c17a55125f5ff6bc002edc6152",
    "id": "qjeWMHrCwSoS"
   },
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "dead5f30514dd02e80463adb162ca508ca34ee74",
    "id": "XBb-sj73pNc7",
    "outputId": "1bfbd6fa-3785-443a-989b-ebd0069613b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.73 s\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading the best saved model to make predictions\n",
    "K.clear_session()\n",
    "model_best = load_model(r'C:\\xampp\\htdocs\\Zoodo\\zoodofoodclassification\\zodoofoodclassification_model.hdf5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = os.listdir(r'C:\\xampp\\htdocs\\Zoodo\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "310fae2c5342c7f432962c4b2e90f09724b5d2c2",
    "id": "5MIBtyj1pFoK"
   },
   "outputs": [],
   "source": [
    "def predict_class(model, images, show = True):\n",
    "  for img in images:\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255.                                      \n",
    "\n",
    "    pred = model.predict(img)\n",
    "    index = np.argmax(pred)\n",
    "    food_list.sort()\n",
    "    pred_value = food_list[index]\n",
    "    if show:\n",
    "        plt.imshow(img[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.title(pred_value)\n",
    "        plt.show()\n",
    "        print(pred_value)\n",
    "        \n",
    "    api_url = 'https://api.calorieninjas.com/v1/nutrition?query='\n",
    "    query = pred_value.replace(\"_\",\" \")\n",
    "    response = requests.get(api_url + query, headers={'X-Api-Key': 's9S3fiY9BWYZtpCebS71Rg==Qk1nbauJKhKE9k8R'})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        print(response.text)\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "75bf083ef761963365a06ed543ac4c33d048ba52",
    "id": "uzLVocClxD0f",
    "outputId": "c8b03921-5cb7-4a37-be70-0351d466d0c5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\xampp\\\\htdocs\\\\Zoodo\\\\zoodofoodclassification\\\\testimage1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mxampp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhtdocs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mZoodo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzoodofoodclassification\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtestimage1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpredict_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mpredict_class\u001b[1;34m(model, images, show)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_class\u001b[39m(model, images, show \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)                    \n\u001b[0;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)         \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\xampp\\\\htdocs\\\\Zoodo\\\\zoodofoodclassification\\\\testimage1.jpg'"
     ]
    }
   ],
   "source": [
    "# Make a list of downloaded images and test the trained model\n",
    "images = []\n",
    "images.append(r'C:\\xampp\\htdocs\\Zoodo\\zoodofoodclassification\\testimage1.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "ef4ab1c2f8402dd1bf1af334e8bc97c9eec2e776",
    "id": "BAXYCwWF8TmY",
    "outputId": "6b012d0b-83a7-4d1b-be12-e1718dc1194c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading the best saved model to make predictions\n",
    "K.clear_session()\n",
    "model_best = load_model('best_model_11class.hdf5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "199eafdf8dd36430f1bd1236e88745471dda2095",
    "id": "9jhn5e607xml",
    "outputId": "914c6fbe-a5ba-4e80-c976-1fcdf93e392c"
   },
   "outputs": [],
   "source": [
    "# Downloading images from internet using the URLs\n",
    "!wget -O fries.jpg https://wallpapercave.com/wp/wp3031767.jpg\n",
    "!wget -O springrolls.jpg https://howtofeedaloon.com/wp-content/uploads/2016/02/bibimbap-1.jpg\n",
    "!wget -O pizza.jpg https://i.pinimg.com/originals/43/0f/83/430f83bfa304c69f4f6c96abbb38223e.jpg\n",
    "!wget -O garlicbread.jpg https://tableagent.s3.amazonaws.com/media/crumbs/xl/229_93.jpg\n",
    "\n",
    "# If you have an image in your local computer and want to tr\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# image = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2be475f3d5bf5146f4c02950faa363a9c8a50ff",
    "id": "HAFb8xSj9Ygn",
    "outputId": "e8122914-ce09-41c0-b2bd-d53787d2c2ae"
   },
   "outputs": [],
   "source": [
    "# Make a list of downloaded images and test the trained model\n",
    "images = []\n",
    "images.append('fries.jpg')\n",
    "images.append('pizza.jpg')\n",
    "images.append('springrolls.jpg')\n",
    "images.append('garlicbread.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e4712669a62fe3d94db12851a6db5dfe3721a4a"
   },
   "source": [
    "### **Model Explainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93d8f5442332a744f63e85254e4606ced953432b"
   },
   "outputs": [],
   "source": [
    "# Load the saved model trained with 3 classes\n",
    "K.clear_session()\n",
    "print(\"Loading the model..\")\n",
    "model = load_model('best_model_3class.hdf5',compile = False)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "970e958f3d2b852aafc8134bd3c999f0f9c27f0c"
   },
   "source": [
    "* **Summary of the model gives us the list of all the layers in the network along with other useful details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aba498e59b48d5c754e4c9658d0265fdf4672ec3"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93c17b10ebd24b31ae7be2f36bf5905fbe6f3ac2"
   },
   "source": [
    "* **Defining some helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "763f8eaa413fe08e4ca740b77f367a3ccfa8864e"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac5fe6f82f0087295b81938da751bc3f6e90bc28"
   },
   "outputs": [],
   "source": [
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    # Build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered.\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # Compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "    # Normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # This function returns the loss and grads given the input picture\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    \n",
    "    # We start from a gray image with some noise\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "\n",
    "    # Run gradient ascent for 40 steps\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce5c9c5a88e68022c5e90399de25124476d1109a"
   },
   "outputs": [],
   "source": [
    "def get_activations(img, model_activations):\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255. \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "    return model_activations.predict(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faa487b2c9aa71ed61acaba24e3bf5902d60dcb5"
   },
   "outputs": [],
   "source": [
    "def show_activations(activations, layer_names):\n",
    "    \n",
    "    images_per_row = 16\n",
    "\n",
    "    # Now let's display our feature maps\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # This is the number of features in the feature map\n",
    "        n_features = layer_activation.shape[-1]\n",
    "\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = layer_activation.shape[1]\n",
    "\n",
    "        # We will tile the activation channels in this matrix\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        # We'll tile each filter into this big horizontal grid\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,\n",
    "                                                 :, :,\n",
    "                                                 col * images_per_row + row]\n",
    "                # Post-process the feature to make it visually palatable\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        # Display the grid\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c26dfe3bc711db01646145bb4308021dfe4a45a"
   },
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d620cf1653800e476661eb6f39043b08efdb17a8"
   },
   "outputs": [],
   "source": [
    "# We start with index 1 instead of 0, as input layer is at index 0\n",
    "layers = [layer.output for layer in model.layers[1:11]]\n",
    "# We now initialize a model which takes an input and outputs the above chosen layers\n",
    "activations_output = models.Model(inputs=model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4621a88d9f09b5579b84fafda9f7beefccd46cc0"
   },
   "source": [
    "**As seen below, the 10 chosen layers contain 3 convolution, 3 batch normalization, 3 activation and 1 max pooling layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab2b5edbbde744049def8d1f82bc108b908b530"
   },
   "outputs": [],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ef3ac62585ea825c4e1e3a789c15e8bb6e5a2a9"
   },
   "source": [
    "**Get the names of all the selected layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec899b27f7042c4f5a01fd2111e9df4133a155bf"
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[1:11]:\n",
    "    layer_names.append(layer.name)\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0607820c01b7fd0ec1b7334218aff8cf80c7d0d"
   },
   "source": [
    "**Provide an input to the model and get the activations of all the 10 chosen layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb23311a44ef7f2ee4db3c015ed0d790fbc7c28e"
   },
   "outputs": [],
   "source": [
    "food = 'applepie.jpg'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd723f92e2fbed1ff7412105f512e42335ea58d7"
   },
   "source": [
    "* **activations** contain the outputs of all the 10 layers which can be plotted and visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "851bf660e561db76f46ed5c6b25aeaafffb5f7d7"
   },
   "source": [
    "**Visualize the activations of intermediate layers from layer 1 to 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57e595c6d6ec1862f58829a214105f94e234bd2c"
   },
   "outputs": [],
   "source": [
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78a622fb2ba644f8d60c7905f1e14c8d6542be4d"
   },
   "source": [
    "**Get the activations for a different input / food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30e9ea4b9b0ecb4fe1a40d971217d9152e278e5"
   },
   "outputs": [],
   "source": [
    "food = 'pizza.jpg'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "929114553760fb3d2e1c8259c65700f1b879e535"
   },
   "outputs": [],
   "source": [
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da0296b7ac03e2c7d725a8d6cd9a3a775a93470a"
   },
   "source": [
    "### **Look into the sparse activations in the layer activation_1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca1fc478ca3f4f8c5a45c8674194860de31648af"
   },
   "outputs": [],
   "source": [
    "# Get the index of activation_1 layer which has sparse activations\n",
    "ind = layer_names.index('activation_1')\n",
    "sparse_activation = activations[ind]\n",
    "a = sparse_activation[0, :, :, 13]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7872185d48380e88e4432e3cdabac26681d6d88"
   },
   "outputs": [],
   "source": [
    "all (np.isnan(a[j][k])  for j in range(a.shape[0]) for k in range(a.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d36fe148ec69c70f9db5e294bd12b8ac5743c05"
   },
   "outputs": [],
   "source": [
    "# Get the index of batch_normalization_1 layer which has sparse activations\n",
    "ind = layer_names.index('batch_normalization_1')\n",
    "sparse_activation = activations[ind]\n",
    "b = sparse_activation[0, :, :, 13]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83f536f8aac24c1e6046f6392ee0ee68d1bc5028"
   },
   "source": [
    "**Show the activation outputs of 1st, 2nd and 3rd Conv2D layer activations to compare how layers get abstract with depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2aa73920abb8c4e96b3f9f1d49c5bc9b3e3384f7"
   },
   "outputs": [],
   "source": [
    "first_convlayer_activation = activations[0]\n",
    "second_convlayer_activation = activations[3]\n",
    "third_convlayer_activation = activations[6]\n",
    "f,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "ax[0].imshow(first_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "ax[0].axis('OFF')\n",
    "ax[0].set_title('Conv2d_1')\n",
    "ax[1].imshow(second_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "ax[1].axis('OFF')\n",
    "ax[1].set_title('Conv2d_2')\n",
    "ax[2].imshow(third_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "ax[2].axis('OFF')\n",
    "ax[2].set_title('Conv2d_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52251160e5b3c0a52f71ff48db78d1d24982ba9a"
   },
   "outputs": [],
   "source": [
    "def get_attribution(food):\n",
    "    img = image.load_img(food, target_size=(299, 299))\n",
    "    img = image.img_to_array(img) \n",
    "    img /= 255. \n",
    "    f,ax = plt.subplots(1,3, figsize=(15,15))\n",
    "    ax[0].imshow(img)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0) \n",
    "    \n",
    "    preds = model.predict(img)\n",
    "    class_id = np.argmax(preds[0])\n",
    "    ax[0].set_title(\"Input Image\")\n",
    "    class_output = model.output[:, class_id]\n",
    "    last_conv_layer = model.get_layer(\"mixed10\")\n",
    "    \n",
    "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "    for i in range(2048):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].set_title(\"Heat map\")\n",
    "    \n",
    "    \n",
    "    act_img = cv2.imread(food)\n",
    "    heatmap = cv2.resize(heatmap, (act_img.shape[1], act_img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed = cv2.addWeighted(act_img, 0.6, heatmap, 0.4, 0)\n",
    "    cv2.imwrite('classactivation.png', superimposed)\n",
    "    img_act = image.load_img('classactivation.png', target_size=(299, 299))\n",
    "    ax[2].imshow(img_act)\n",
    "    ax[2].set_title(\"Class Activation\")\n",
    "    plt.show()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b24d222ab15dccc36f58d048cdd450531780b43"
   },
   "outputs": [],
   "source": [
    "print(\"Showing the class map..\")\n",
    "print(class_map_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e67af6ec477f5c1c552eabf2a279a7a4d0321542"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('applepie.jpg')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba1376f87f8921015cd6a9c2cee1f2a31603ff7b"
   },
   "source": [
    "###  **See how the class activation map looks for a different image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7703de1adbb3c7c4d36a156255cac7544a753ec9"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('pizza.jpg')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50d3b1b85f1e1521f241f9da8a66337b4c2b4081"
   },
   "source": [
    "### **Lets see if we can break the model or see what it does when we surpise it with different data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f6b15f42226445649a7efde851c3c34cfd12976"
   },
   "outputs": [],
   "source": [
    "!wget -O piepizza.jpg https://raw.githubusercontent.com/theimgclist/PracticeGround/master/Food101/piepizza.jpg\n",
    "!wget -O piepizzas.png https://raw.githubusercontent.com/theimgclist/PracticeGround/master/Food101/piepizzas.png\n",
    "!wget -O pizzapie.jpg https://raw.githubusercontent.com/theimgclist/PracticeGround/master/Food101/pizzapie.jpg\n",
    "!wget -O pizzapies.png https://raw.githubusercontent.com/theimgclist/PracticeGround/master/Food101/pizzapies.png    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bd18ee85715a2c5ea93ac42c90f5013371e9606"
   },
   "outputs": [],
   "source": [
    "food = 'piepizza.jpg'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3002cc239b1e6cc18d87a5cf68422f779a5feb4d"
   },
   "outputs": [],
   "source": [
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d586ebc28865f330533978285cdb86ea0b034e4"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('piepizza.jpg')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ee84660d1c611e26210c8fdd039eed0582f9c17"
   },
   "outputs": [],
   "source": [
    "food = 'pizzapie.jpg'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dea63dad490095884d23d17ba3408a783ef7221"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('pizzapie.jpg')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "486e22e0a40bea49f7c2bffca914cee10bce049a"
   },
   "source": [
    "### **More surprise data to the model...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94f1df50e0160a18fd4fc8be1415f53ffa5aa4d1"
   },
   "outputs": [],
   "source": [
    "food = 'pizzapies.png'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30039ce99f4d49bb562cb08014a98691ec1d1ef0"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('pizzapies.png')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4215643fc7ea4ea01003105c36d75ac8643f636"
   },
   "outputs": [],
   "source": [
    "food = 'piepizzas.png'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea41b1a1ee4f286d736a7b582151e15619ca4666"
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('piepizzas.png')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
